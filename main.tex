\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\title{Rapport Apprentissage Automatique}
\author{Gabin Marc Mberi-Kongo, Quentin Vigne, Vincent Deschaud}
\author{Thomas Cambon, Florent Jakubowski }
\author{
  Gabin Marc Mberi-Kongo\\
  \texttt{gabin.mberi-kongo@univ-lyon2.fr}
  \and
  Quentin Vigne\\
  \texttt{quentin.vigne@univ-lyon2.fr}
  \and
  Vincent Dechaud\\
  \texttt{vincent.dechaud@univ-lyon2.fr}
  \and
  Thomas Cambon\\
  \texttt{t.cambon@univ-lyon2.fr}
  \and
  Florent Jakubowski\\
  \texttt{florent.jakubowski@univ-lyon2.fr}
}
\date{February 2021}

\usepackage{natbib}
\usepackage{graphicx}

\begin{document}

\maketitle

\tableofcontents

\section{Introduction}

Dans le cadre du module Apprentissage supervisé dispensé par Monsieur Ah-pine, nous avons eu le choix d'implémenter un algorithme d'apprentissage supervisé parmi plusieurs et de tester ses performances par rapport à d'autres méthodes d'apprentissage supervisé. 

\section{Sujet}
Nous avons choisis parmis les 4 sujets proposés le sujet sur l'algorithme Adaboost.
\section{Problématiques scientifiques}
La problématique scientifique pour ce projet est de vérifier l'intérêt des méthodes dites d'ensembles pour la classification binaire et multiclasses, plus spécifiquement l'algorithme Adaboost. L'enjeux sera d'observer la différence de performance entre des méthodes d'apprentissage supervisé ne se basant pas sur une prédiction par comité et des méthodes qui au contraire utilisent le vote par comité pour faire leur prédiction.
Nous sommes appuyés sur l'implémentation de l'algorithme adaboost et de sa variante l'algorithme Adaboost M1 telle que décrite dans le 'papier' de Freund et Schapire \citep{FreundSchapire1996} en 1996 pour reimplémenter nos algorithmes.

\section{Fondements, principes et état de l'art}
Le fondement de l'Adaboost part du principe d'algorithmes de "Boosting" introduit par Yoav Freund et Robert Schapire en juillet 1996 dans l'article "Experiments with a new boosting algorithm". Le but de ce nouvel algorithme de boosting est de réduire significativement l'erreur générée par les classifieurs faibles qui donnent un score à peine meilleur qu'un classifieur aléatoire. Ces classifieurs sont dénommés "classifieurs faibles" ou bien "Weak Learner" dans l'article original. Ce fût la première méthode fonctionnelle permettant de mettre en oeuvre le principe de boosting.

Souvent le bagging et le boosting sont confondus puisque ces deux méthodes sont toutes les deux des méthodes ensemblistes. Le boosting que nous étudions ici va attribuer un poids plus fort aux classifieurs ayant prédit correctement que ceux dont la prédiction est incorrecte. Adaboost s'appuie sur ce principe en donnant plus d'importance aux valeurs compliquées à prédire. On booste les classifieurs qui réusissent lorsque d'autres échouent.


\section{Implémentation}
Le but de cette partie est d'explicité d'une part les détails techniques et l'organisation du code (5.1, 5.2, 5.4) et d'autre part notre organisation en tant qu'équipe et la manière dont nous avons réalisé ce code (5.3 Workflow)
le langage utilisé, le workflow, les différentes fonctions et leur spécification (comment avez-vous réalise, organisé votre code et avec quels outils ?)
\subsection{Langage et librairies utilisés}
Nous avons utilisé le langage python pour développer notre code. Ce choix a été motivé par la simplicité d'implémentation et de compréhension du code, de plus l'accès à de nombreuse librairies comme panda ou scikit-learn était très intéressant dans notre cas. 

Ci-suit la liste des librairies python utilisées dans ce projet : 
\begin{itemize}
  \item Numpy : Numpy est une bibliothèque que nous utilisons pour le calcul matricielle et sur des tableaux de plusieurs dimensions.
  \item Pandas : Pandas est une bibliothèque permettant de manipuler des données également en python. Nous nous en servons pour charger des données depuis un csv dans des dataframe pandas et pouvoir ensuite effectuer des opérations dessus.
  \item Scikit-learn : Scikit-learn est une bibliothèque destiné à l'apprentissage automatique. Elle fournit de nombreuses classes d'algorithmes d'apprentissage supervisé très simple à manipuler, des fonctions pour séparer son jeu de données en deux jeu de données d'entrainement et de test, et d'autres fonctions intéressantes permettant de visualiser les résultats de nos entrainements.
  \item os : Os est un module de base de python, il permet d'utiliser les fonctionnalités dépendantes du système d'exploitation. Nous nous en servons pour définir un répertoire courant au moment de l'éxécution de notre code et ainsi défénir un chemin relatif pour charger notre csv de données.
\end{itemize}

\subsection{Workflow}

Pour le développement du code nous avons adopté une organisation basique semblable aux organisation agile que l'on peut retrouver dans le milieu professionnelle. 
Nous avons diviser le travail en tâches et nous nous les sommes attribuées au fur et à mesure du projet. Nous avions un tableau kanban rudimentaire avec des états 'Nouvelle tâche', 'A faire', 'En cours' et 'Terminé'. Nous passions les items à travers les différentes colonnes en fonction de l'état de la tâche. Cela nous a permis de bien nous répartir le travail et de suivre l'avancement du projet. 

\paragraph{Intégration continue}

Nous étions tous d'accord pour versionner dès le début notre code. Pour ce faire nous avons eu recours a l'outil de versionning Git. 
Pour partager notre code nous nous sommes tournés vers le site Github qui permet un stockage des différentes version du code dans un dépôt (repository en anglais) virtuel, c'est-à-dire hébergé sur l'un de leur serveur.

Pour chaque tâche nous réalisions une nouvelle branche sur notre environnement locale puis une fois terminée nous l'envoyions sur le dépôt distant via une demande d'ajout ('Pull request'). 
Le code était ainsi relu par un ou plusieurs camarade pour s'assurer qu'il soit fonctionnel et compréhensible de tous. Une fois cette étape de validation passée nous ajoutions le code au code existant. 

Toute cette organisation nous a permit d'itérer sur le projet et de mettre en commun le code développer par chacun de manière propre et organisée. 

\subsection{Organisation du code}

Dans le dossier src/adaboost réside les différentes implémentations de l'algorithme adaboost avec les fichiers utiles aux chargements des données et à la comparaison avec d'autres algorithmes d'apprentissage supervisés.

Pour l'implémentation nous avons choisis le paradigme de l'orienté objet, c'est-à-dire une approche par classe. Il existe une classe par fichier .py avec pour chaque des méthodes spécifiques. 

Seulement les fichiers main.py et cleanCSV.py contiennent des fonctions et non des classes. Le paradigme de la programmation fonctionnelle nous parassait plus adapté, étant que donnée que nous éxécutons chargions ou tranformions principalement des données grâce à ces fichiers.  

\paragraph{Partie classification binaire : }
\begin{itemize}
  \item weakleaner.py : classe weakleaner
  \begin{itemize}
    \item constructor
    \item make\_stump\_prediction
    \item calculate\_error\_rate
    \item display\_stump
  \end{itemize}
  \item adaboost\_binary.py : classe 
  \begin{itemize}
          \item constructor
            \item fit
            \item predict
            \item calculate\_error
    \end{itemize}
  \item adaboost\_binary\_benchmark.py : classe benchmark\_performance
  \begin{itemize}
          \item constructor
          \item print\_benchmark\_res
          \item get\_benchmark\_errors
    \end{itemize}
  \item cleanCSV\_adaboost\_binary.py : fonction format\_kickstarter\_datas
  \begin{itemize}
            \item format\_kickstarter\_datas
    \end{itemize}
  \item main\_binary.py :
  \begin{itemize}
          \item load\_data
          \item main
    \end{itemize}

\end{itemize}

\paragraph{Partie classification multiclasse : }


\begin{itemize}
  \item weakleaner\_M1\_multiclass.py : classe weakleaner
  \begin{itemize}
    \item constructor
    \item make\_stump\_prediction
    \item calculate\_error\_rate
    \item display\_stump
  \end{itemize}
  \item adaboostM1\_multiclass.py : classe 
  \begin{itemize}
    \item constructor
    \item fit
    \item predict
    \item calculate\_error
  \end{itemize}
  \item adaboostM1\_multiclass\_benchmark : classe benchmark\_performance
  \begin{itemize}
        \item constructor
        \item print\_benchmark\_res
        \item get\_benchmark\_errors
    \end{itemize}
  \item cleanCSV\_M1\_multiclass : fonction format\_kickstarter\_datas
  \begin{itemize}
        \item format\_kickstarter\_datas
    \end{itemize}
  \item main\_multiclass.py :
  \begin{itemize}
          \item load\_data
          \item main
    \end{itemize}
\end{itemize}


\section{Présentation du jeu de données}

Pour ce projet, nous avons choisi d'utiliser un jeu de données avec différentes informations sur des projets Kickstarter de 2018. Kickstarter est une entreprise de financement participatif qui donne la possibilité aux internautes de financer des projets qui n'ont pas encore été développés.\newline 

\noindent Le fichier csv que nous avons utilisé contient les variables suivantes : \newline 
\begin{itemize}
    \item ID du projet (ID)
    \item Nom du projet (NAME)
    \item Catégorie principale (MAIN\_CATEGORY)
    \item Sous-catégorie (CATEGORY)
    \item Monnaie utilisée (CURRENCY)
    \item Date limite pour le financement participatif (DEADLINE)
    \item Somme d'argent (GOAL) que souhaite récolter un créateur pour financer son projet (si la somme n'est pas atteinte, le projet ne sera pas financé et le créateur ne recevra pas d'argent)
    \item Date de lancement du projet (LAUNCHED)
    \item Montant total promis par les contributeurs pour le projet (PLEGED)
    \item Nombre de contributeurs (BACKERS)
    \item Pays (COUNTRY)
    \item Conversion en USD (USD\_PLEGED) du montant total promis par les contributeurs pour le projet (conversion effectuée par kickstarter) 
    \item Conversion en USD (USD\_PLEGED\_REAL) du montant total promis par les contributeurs pour le projet (conversion depuis l'API Fixer.io)
    \item Et enfin la somme d'argent que souhaite récolter un créateur pour financer son projet, convertie en USD (USD\_GOAL\_REAL).\newline 

\end{itemize}

\noindent La variable que l'on essayera de prédire est l'état du projet (STATE). Six états sont possibles :

\begin{itemize}
    \item Projet réussi (successfull)
    \item Projet échoué (failed)
    \item Projet en cours (live)
    \item Projet annulé (canceled)
    \item Projet suspendu (suspended)
    \item Ou projet non défini (undefined).\newline 
\end{itemize}

\noindent Voici un extrait des données :

\begin{center} \includegraphics[scale=0.55]{extrait_donnees_partie1.PNG} \end{center}
\begin{center} \includegraphics[scale=0.55]{extrait_donnees_partie2.PNG} \end{center}
\noindent Ce jeu de données est intéressant car il a un nombre important d'individus et de variables. De plus, il possède à la fois des variables catégorielles et numériques, ce qui donne de la variété dans les types de variables. \newline

\noindent Pour la suite, nous avons décidé de supprimer les colonnes ID et NAME car ce sont deux variables qui ont des valeurs uniques pour chacun des projets. Nous avons également supprimé les variables GOAL, PLEGED et USD\_PLEGED pour ne garder qu'une unique version de ces variables avec la devise USD.\newline

\noindent Nous conserverons uniquement les projets à l'état "successful" ou "failed" pour l'algorithme adaboost binaire. "Successful" prendra la valeur 1 et "failed" la valeur 0.\newline

\noindent Pour l'extension adaboost.M1 (problèmes multiclasses), nous garderons cette fois-ci tous les individus.


\section{Le protocole expérimental}

Nous souhaitons comparer nos algorithmes implémentés avec d'autres algorithmes de classification supervisé. Ces algorithmes sont issues de la librairie "Scikit-Learn", qui est une librairie de machine learning très prisé des utilisateurs de Python. Les algorithmes choisis vont du plus basique, en partant des moindres carrés ordinaires, et allant vers des algorithmes concurents d'Adaboost.

Les algorithmes testés sont les suivants :
\begin{itemize}
    \item Moindres Carrés ordinaires 
    \item Régression Logistique
    \item Arbre de décision
    \item SVM
    \item Random Forest
    \item Bagging
    \item Ada Boost
\end{itemize}

Tous les algorithmes ont été utilisés sur les mêmes données d'apprentissage et de test, avec le même nombre d'itération. Allant de 1 à 500.

%Pour le protocole expérimental nous avons choisis plusieurs autres algorithmes d'apprentissage supervisé n'utilisant pas le vote par comité. 

%Pour la classification binaire nous avons choisis les algorithmes suivant : 
%Pour la classification multiclasse nous avons choisis les algorithmes suivant : 

%Nous avons entrainé nos 2 algorithmes et les autres algorithmes avec le même nombre d'époques et le même data set. 
%Puis nous avons comparé leurs prédictions avec les prédictions des autres algorithmes choisis à l'aide d'une fonction d'erreur.

%La fonction d'erreur calcule le pourcentage de mauvaises prédictions données sur les données de test. 

\section{les résultats expérimentaux et leurs analyses}
Tableau des résultats exprimentaux obtenus

\begin{center}
    \begin{tabular}{| l | l | l | l |}
    \hline
    Algorithme & 1 itérations & 10 itérations & 50 itérations \\ \hline
    Régression Linéaire & 0.36087 &  0.36087 &  0.36087 
    \\ \hline
    Régression Logistique & 0.39232 & 0.05242 & 0.00575  \\ \hline
    SVM & 0.27555 & 0.29000 & 0.14666  \\ \hline
    Arbre de décision & 0.00707 & 0.00676 & 0.00656 \\ \hline
    Adaboost binaire & 0.16202 & 0.08666 & 0.03161 \\
    \hline
    \end{tabular}
\end{center}


\section{Une discussion scientifique/analyse critique}

\section{Conclusion}
Ici c'est la conclusion 
C'est terminé

\bibliographystyle{plain}
\bibliography{references}
\end{document}
